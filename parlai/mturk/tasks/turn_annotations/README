### Turn Annotations MTurk Task

This task will collect conversations between a human and a model. After each response by the model, the human will be prompted to annotate the model's response by selecting  checkboxes that represent customizable attributes of that response.

This script can be run either on the command line or via a Python launch script. See `launch.py` for an example launch script. Some parameters you can set include the models to run (and what folder the models are found in), where to save data, etc.

(((TODO: minimal sample command-line command)))

(((give descriptions of all 5 files to pass in)))

(((Say that you can pass in args as separate files on the command line or as args; show an example of this, where there's a flag for each one)))

In `worlds.py`, modify `TurnAnnotationsOnboardWorld.check_onboarding_answers()` to change the worker selection criteria.

**WARNING**: Code is somewhat rough around the edges, and it uses the legacy version of the ParlAI MTurk integration

[[[TODO: delete all below once you've rewritten the above]]]

Modify constants.py with HTML for the task description (shown when the worker
first enters the task) and the left pane (shown on the left during the
conversation).

Customize ONBOARD_TASK_DATA in constants.py to provide your own onboarding
conversation and answers.

Customize the buckets you want to collect per turn in constants.py as well.
